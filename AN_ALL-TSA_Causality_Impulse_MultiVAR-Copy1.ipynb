{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import xuleta as xu\n",
    "from scipy import stats\n",
    "from functools import reduce\n",
    "import os\n",
    "month_names = pd.date_range(start='2016-01-01', periods=12, freq='MS').strftime('%b')\n",
    "\n",
    "\n",
    "##for SQL\n",
    "#from sqlalchemy import create_engine\n",
    "#engine = create_engine('postgresql://denis:sinedoom48@localhost:5432/drought')\n",
    "fout = '/Users/denismariano/pcloud/PB_carlos/Document/elsevier_sample/images/'#mac\n",
    "fout = '/home/denis/pcloud/0NEWPROJ/plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO COMPARE THIS GROUPS WITH THE HCC GROUPS\n",
    "regions = [41004, 41005, 41007, 41008, 41009, 41010, 41011, 41012, 41013, 41014, 41015, 41019, \n",
    "           41020, 41021, 41022, 41023, 41024, 41027, 41028, 41029, 41030, 42003, 43005,  43008, \n",
    "           43009, 43010, 43011, 43012, 43017]\n",
    "\n",
    "grouped = [[41019,41020, 41021], #ce-PR\n",
    "           [41007, 41008, 41009, 41010, 41011, 41012, 41013, 41014, 41015], #cn-PR\n",
    "           [41004, 41005,41022, 41023, 41024], #cw-PR\n",
    "           [41027, 41028, 41029, 41030, 42003], #sw-PR\n",
    "           [43005,  43008,43009, 43010, 43011, 43012, 43017]] #nw-RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/235039/statsmodels-clarification-on-varp-results-attribute-results-forecast-interva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def piv_table(var,lista,resample='M'):\n",
    "    region_var = weightaverage(var,lista)\n",
    "    region_var = pd.DataFrame(region_var)\n",
    "    region_var.columns = ['values']\n",
    "    region_var = region_var.resample('M').mean()\n",
    "\n",
    "    region_var['year'] = region_var.index.year\n",
    "    region_var['month'] = region_var.index.month\n",
    "    region_var_piv = region_var.pivot(index='year', columns='month', values='values')\n",
    "    region_var_piv.columns = month_names\n",
    "    return region_var_piv\n",
    "\n",
    "def weightaverage(var,region_number,area):\n",
    "    '''\n",
    "        var (pandas DataFrame): dataset containing the variable, either extracted from SQL or CSV, or the z-score of it\n",
    "        region_number (int): group number (from grouped, in this case)\n",
    "        area (float): threshold for minimum area to be considered for a municipality to be included in the weight average\n",
    "    '''\n",
    "\n",
    "    #area threshold -> I HAVE TO VERIFY WHAT THESE AREAS MEAN IN THE MAP\n",
    "\n",
    "    l = list(aux[(aux['microrregi'].isin(grouped[region_number])) & (aux['area']> area)].geocodig_m)\n",
    "    a = aux[aux['geocodig_m'].isin(l)]\n",
    "    a['w'] = a.area/sum(a.area)\n",
    "    a = a[['geocodig_m','w']]\n",
    "    a.index = a.geocodig_m\n",
    "    a.drop(\"geocodig_m\",inplace=True,axis=1)\n",
    "    a = a.T\n",
    "    var_aw = pd.DataFrame(var[a.columns].values*a.values, columns=a.columns,index=var[a.columns].index)\n",
    "    var_final = var_aw.sum(axis=1,skipna=True)\n",
    "    var_final.index = pd.DatetimeIndex(var_final.index)\n",
    "    print('A total of %d municipalities were considered' %var_aw.shape[1])\n",
    "    return(var_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 52.3 ms, total: 3.07 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MODIS ET\n",
    "et = pd.read_csv(\"../SQL/drought_consultas_br_et.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"geocodig_m\",values=\"mean\").interpolate()\n",
    "\n",
    "# MODIS LAI\n",
    "lai = pd.read_csv(\"../SQL/drought_consultas_br_lai.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"geocodig_m\",values=\"mean\").interpolate()\n",
    "\n",
    "#FILTERED NDVI\n",
    "ndvi = pd.read_csv(\"../SQL/drought_consultas_br_ndvi.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"geocodig_m\",values=\"mean\").interpolate()\n",
    "\n",
    "# ESI\n",
    "esi = pd.read_csv(\"../SQL/drought_consultas_br_esi.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"geocodig_m\",values=\"mean\").interpolate()\n",
    "\n",
    "esir = pd.read_csv(\"../SQL/drought_consultas_br_esi_regioes.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"subgrupo2\",values=\"mean\").interpolate()\n",
    "\n",
    "# GLEAM SM Root abs\n",
    "smrootabs = pd.read_csv(\"../SQL/drought_consultas_br_sm_root_abs_region.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"subgrupo2\",values=\"mean\").interpolate()\n",
    "\n",
    "# GLEAM SM Root anom\n",
    "smrootanom = pd.read_csv(\"../SQL/drought_consultas_br_sm_root_anom_region.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"subgrupo2\",values=\"mean\").interpolate()\n",
    "\n",
    "# GLEAM SM surface abs\n",
    "smrootabs = pd.read_csv(\"../SQL/drought_consultas_br_sm_surf_abs_region.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"subgrupo2\",values=\"mean\").interpolate()\n",
    "\n",
    "# GLEAM SM surface anom\n",
    "smrootanom = pd.read_csv(\"../SQL/drought_consultas_br_sm_surf_anom_region.csv\").pivot_table(index=\"acquisition\",\n",
    "                   columns=\"subgrupo2\",values=\"mean\").interpolate()\n",
    "\n",
    "#CROP AREAS  \n",
    "aux = pd.read_csv(\"../SQL/drought_consultas_br_aux_big_sul_crop.csv\")\n",
    "\n",
    "# LIST OF MUNICIPALITIES, MESO, MICROregions\n",
    "sulmuni = pd.read_csv(\"../SQL/sul_muni.csv\")\n",
    "sulmuni.drop([\"sigla\",\"nome_muni\",\"muni\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A t this point, GLEAM data is already given in regions (not agro). I am wondering if I should re-extract the other data to regions (either crop areas or just regions). **\n",
    "* MODIS data definitely have to be extracted by crop mask\n",
    "* CHIRPS data definitely by area (region)\n",
    "* ESI data is tricky, I should try by crop regionalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGING data: aux with soy_null occurrence... kinda useless\n",
    "aux = pd.merge(aux, sulmuni[[\"soy_null\",\"geocodig_m\"]], on='geocodig_m')\n",
    "aux = aux[aux[\"soy_null\"]<1].drop(\"soy_null\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>microrregi</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geocodig_m</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4102703</th>\n",
       "      <td>123048</td>\n",
       "      <td>2517.818024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103602</th>\n",
       "      <td>369144</td>\n",
       "      <td>4089.357875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124103</th>\n",
       "      <td>164064</td>\n",
       "      <td>1701.234461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            microrregi         area\n",
       "geocodig_m                         \n",
       "4102703         123048  2517.818024\n",
       "4103602         369144  4089.357875\n",
       "4124103         164064  1701.234461"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [4102703.0, 4103602.0, 4124103.0]\n",
    "pd.options.mode.chained_assignment = None #error omit\n",
    "a = aux[aux['geocodig_m'].isin(lista)].groupby(\"geocodig_m\").sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 175 municipalities were considered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "acquisition\n",
       "2001-01-09    0.734346\n",
       "2001-01-17    0.706319\n",
       "2001-01-25    0.670538\n",
       "2001-02-02    0.669410\n",
       "2001-02-10    0.658840\n",
       "2001-02-18    0.640827\n",
       "2001-02-26    0.651764\n",
       "2001-03-06    0.654210\n",
       "2001-03-14    0.605261\n",
       "2001-03-22    0.555148\n",
       "2001-03-30    0.541412\n",
       "2001-04-07    0.511706\n",
       "2001-04-15    0.489608\n",
       "2001-04-23    0.457270\n",
       "2001-05-01    0.459219\n",
       "2001-05-09    0.473734\n",
       "2001-05-17    0.484634\n",
       "2001-05-25    0.507950\n",
       "2001-06-02    0.561555\n",
       "2001-06-10    0.583078\n",
       "2001-06-26    0.603208\n",
       "2001-07-04    0.629204\n",
       "2001-07-12    0.651518\n",
       "2001-07-20    0.660698\n",
       "2001-07-28    0.671777\n",
       "2001-08-05    0.671190\n",
       "2001-08-13    0.667455\n",
       "2001-08-21    0.650651\n",
       "2001-08-29    0.634266\n",
       "2001-09-06    0.561227\n",
       "                ...   \n",
       "2016-10-23    0.514743\n",
       "2016-10-31    0.514752\n",
       "2016-11-08    0.509534\n",
       "2016-11-16    0.526095\n",
       "2016-11-24    0.544274\n",
       "2016-12-02    0.589172\n",
       "2016-12-10    0.644421\n",
       "2016-12-18    0.688068\n",
       "2016-12-26    0.731170\n",
       "2017-01-01    0.714869\n",
       "2017-01-09    0.679541\n",
       "2017-01-17    0.643434\n",
       "2017-01-25    0.664935\n",
       "2017-02-02    0.654258\n",
       "2017-02-10    0.663751\n",
       "2017-02-18    0.670846\n",
       "2017-02-26    0.643704\n",
       "2017-03-06    0.587162\n",
       "2017-03-14    0.523299\n",
       "2017-03-22    0.510440\n",
       "2017-03-30    0.496106\n",
       "2017-04-07    0.507650\n",
       "2017-04-15    0.512646\n",
       "2017-04-23    0.535094\n",
       "2017-05-01    0.551807\n",
       "2017-05-09    0.569787\n",
       "2017-05-17    0.584163\n",
       "2017-05-25    0.602917\n",
       "2017-06-02    0.620819\n",
       "2017-06-10    0.632092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area= 10\n",
    "weightaverage(ndvi,region_number=0,area=area)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are using crop areas! \n",
    "* the weighted averages have to be calculated based on crop areas rather than municipalities areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing LIST of muni which we have data versus list of munic which we have area information\n",
    "[x for x in df[41015] if str(x) != 'nan']==list(aux[aux[\"microrregi\"]==str(41015)].geocodig_m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    print([x for x in df[i] if str(x) != 'nan']==list(aux[aux[\"microrregi\"]==str(i)].geocodig_m ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x for x in df[41015] if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightaverage(et,[x for x in df[41001] if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_et = pd.DataFrame()\n",
    "for i in df.columns:\n",
    "    avg = weightaverage(et,[x for x in df[i] if str(x) != 'nan'])\n",
    "    #df_et[i] = pd.Series(avg)\n",
    "    print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR\n",
    "http://www.statsmodels.org/dev/vector_ar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import *\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = ['2002-08','2016-12']\n",
    "reg = cern\n",
    "def construir(reg,dates):\n",
    "\n",
    "\n",
    "    e = weightaverage(esi,reg).loc[dates[0]:dates[1]].to_frame()\n",
    "    g = weightaverage(zgpp,reg).loc[dates[0]:dates[1]].to_frame()\n",
    "    a = weightaverage(zalbedo,reg).loc[dates[0]:dates[1]].to_frame()\n",
    "    p = weightaverage(zprec,reg).loc[dates[0]:dates[1]].to_frame()\n",
    "    dfs = [e,g,a,p]\n",
    "    final = reduce(lambda left,right: pd.merge(left,right, how='outer',\n",
    "                                               right_index=True,left_index=True), dfs)\n",
    "    final.columns = [['ESI','zGPP','zAlbedo','zPrec']]\n",
    "    final = final.interpolate('values',limit_direction='both')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_c = construir(cern,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_1 = construir(nd1,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_2 = construir(nd2,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_3 = construir(nd3,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_4 = construir(nd4,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_5 = construir(nd5,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_b = construir(ba1+ba2,dates).resample('W').mean().loc['2002-08':'2016-12']\n",
    "df_p = construir(pi1+pi2,dates).resample('W').mean().loc['2002-08':'2016-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = VAR(df_c)\n",
    "m1 = VAR(df_1)\n",
    "m2 = VAR(df_2)\n",
    "m3 = VAR(df_3)\n",
    "m4 = VAR(df_4)\n",
    "m5 = VAR(df_5)\n",
    "mb = VAR(df_b)\n",
    "mp = VAR(df_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1.select_order(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = int(np.round((12*len(df_c)/100)**.25,0)+1)\n",
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = mc.fit(maxlags=ml,ic='bic')\n",
    "r1 = m1.fit(maxlags=ml,ic='bic')\n",
    "r2 = m2.fit(maxlags=ml,ic='bic')\n",
    "r3 = m3.fit(maxlags=ml,ic='bic')\n",
    "r4 = m4.fit(maxlags=ml,ic='bic')\n",
    "r5 = m5.fit(maxlags=ml,ic='bic')\n",
    "rb = mb.fit(maxlags=ml,ic='bic')\n",
    "rp = mp.fit(maxlags=ml,ic='bic')\n",
    "#print(rc.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rc.forecast(df_c.values[-rc.k_ar:], 6)\n",
    "rc.plot_forecast(20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impulse response analysis\n",
    "Lutkepohl 262(274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 10\n",
    "irfc = rc.irf(l)\n",
    "irf1 = r1.irf(l)\n",
    "irf2 = r2.irf(l)\n",
    "irf3 = r3.irf(l)\n",
    "irf4 = r4.irf(l)\n",
    "irf5 = r5.irf(l)\n",
    "irfp = rp.irf(l)\n",
    "irfb = rb.irf(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irfc.plot(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(irfc.orth_irfs[:,0,1], lw=1.5, label='ND6+CERN', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A BIG PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ORTHOGONALIZED\n",
    "\n",
    "plt.style.use('seaborn-paper')#bmh\n",
    "#https://matplotlib.org/devdocs/gallery/style_sheets/style_sheets_reference.html\n",
    "#fivethirtyeight\n",
    "#ggplot\n",
    "params = {'legend.fontsize': 11,\n",
    "         #'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':12,\n",
    "         'xtick.labelsize':12,\n",
    "         'ytick.labelsize':12,\n",
    "         'lines.linewidth':1,\n",
    "         'figure.titlesize':16,\n",
    "         #'axes.titleweight': 'bold' \n",
    "         }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3, figsize=(12,7),sharex=True)#, sharey=True\n",
    "\n",
    "#IRFS\n",
    "ax1.plot(irf1.orth_irfs[:,0,1], lw=1.5, label='ND1')\n",
    "ax1.plot(irf2.orth_irfs[:,0,1], lw=1.5, label='ND2')\n",
    "ax1.plot(irf3.orth_irfs[:,0,1], lw=1.5, label='ND3')\n",
    "ax1.plot(irf4.orth_irfs[:,0,1], lw=1.5, label='ND4')\n",
    "ax1.plot(irf5.orth_irfs[:,0,1], lw=1.5, label='ND5')\n",
    "ax1.plot(irfc.orth_irfs[:,0,1], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax1.plot(irfp.orth_irfs[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax1.plot(irfb.orth_irfs[:,0,1], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax1.axhline(y=0, color='grey', alpha=.75)\n",
    "ax1.set_title('a) zGPP -> ESI', x=.05, y=.90, ha='left')\n",
    "#ax1.legend(loc=2, ncol=1, frameon=True, fancybox=True, lw=1.5, labelspacing=0.1)\n",
    "\n",
    "ax2.plot(irf1.orth_irfs[:,0,2], lw=1.5, label='ND1')\n",
    "ax2.plot(irf2.orth_irfs[:,0,1], lw=1.5, label='ND2')\n",
    "ax2.plot(irf3.orth_irfs[:,0,1], lw=1.5, label='ND3')\n",
    "ax2.plot(irf4.orth_irfs[:,0,1], lw=1.5, label='ND4')\n",
    "ax2.plot(irf5.orth_irfs[:,0,1], lw=1.5, label='ND5')\n",
    "ax2.plot(irfc.orth_irfs[:,0,2], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax2.plot(irfp.orth_irfs[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax2.plot(irfb.orth_irfs[:,0,2], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax2.axhline(y=0, color='grey', alpha=.75)\n",
    "ax2.set_title('b) zAlbedo -> ESI', x=.05, y=.90, ha='left')\n",
    "#ax2.legend(loc=2, ncol=1, frameon=True, fancybox=True, lw=1.5, labelspacing=0.1)\n",
    "\n",
    "ax3.plot(irf1.orth_irfs[:,0,3], lw=1.5, label='ND1')\n",
    "ax3.plot(irf2.orth_irfs[:,0,1], lw=1.5, label='ND2')\n",
    "ax3.plot(irf3.orth_irfs[:,0,1], lw=1.5, label='ND3')\n",
    "ax3.plot(irf4.orth_irfs[:,0,1], lw=1.5, label='ND4')\n",
    "ax3.plot(irf5.orth_irfs[:,0,1], lw=1.5, label='ND5')\n",
    "ax3.plot(irfc.orth_irfs[:,0,3], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax3.plot(irfp.orth_irfs[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax3.plot(irfb.orth_irfs[:,0,3], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax3.axhline(y=0, color='grey', alpha=.75)\n",
    "ax3.set_title('c) zPrec -> ESI', x=.05, y=.90, ha='left')\n",
    "#ax3.legend(loc=2, ncol=1, frameon=True, fancybox=True, lw=1.5, labelspacing=0.1)\n",
    "\n",
    "#Cum_IRFS\n",
    "ax4.plot(irf1.orth_cum_effects[:,0,1], lw=1.5, label='ND1')\n",
    "ax4.plot(irf2.orth_cum_effects[:,0,1], lw=1.5, label='ND2')\n",
    "ax4.plot(irf3.orth_cum_effects[:,0,1], lw=1.5, label='ND3')\n",
    "ax4.plot(irf4.orth_cum_effects[:,0,1], lw=1.5, label='ND4')\n",
    "ax4.plot(irf5.orth_cum_effects[:,0,1], lw=1.5, label='ND5')\n",
    "ax4.plot(irfc.orth_cum_effects[:,0,1], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax4.plot(irfp.orth_cum_effects[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax4.plot(irfb.orth_cum_effects[:,0,1], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax4.axhline(y=0, color='grey', alpha=.75)\n",
    "ax4.set_title('d) zGPP -> ESI', x=.05, y=.90, ha='left')\n",
    "ax4.set_xlabel('period (week)', fontsize=12)\n",
    "\n",
    "#ax4.legend(loc=2, ncol=1, frameon=True, fancybox=True, lw=1.5, labelspacing=0.1)\n",
    "ax5.plot(irf1.orth_cum_effects[:,0,2], lw=1.5, label='ND1')\n",
    "ax5.plot(irf2.orth_cum_effects[:,0,1], lw=1.5, label='ND2')\n",
    "ax5.plot(irf3.orth_cum_effects[:,0,1], lw=1.5, label='ND3')\n",
    "ax5.plot(irf4.orth_cum_effects[:,0,1], lw=1.5, label='ND4')\n",
    "ax5.plot(irf5.orth_cum_effects[:,0,1], lw=1.5, label='ND5')\n",
    "ax5.plot(irfc.orth_cum_effects[:,0,2], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax5.plot(irfp.orth_cum_effects[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax5.plot(irfb.orth_cum_effects[:,0,2], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax5.axhline(y=0, color='grey', alpha=.75)\n",
    "ax5.set_title('e) zAlbedo -> ESI', x=.05, y=.90, ha='left')\n",
    "ax5.legend(loc='best', ncol=1, frameon=True, fancybox=True,  labelspacing=0.1).get_frame().set_alpha(0.7)\n",
    "ax5.set_xlabel('period (week)', fontsize=12)\n",
    "\n",
    "ax6.plot(irf1.orth_cum_effects[:,0,3], lw=1.5, label='ND1')\n",
    "ax6.plot(irf2.orth_cum_effects[:,0,1], lw=1.5, label='ND2')\n",
    "ax6.plot(irf3.orth_cum_effects[:,0,1], lw=1.5, label='ND3')\n",
    "ax6.plot(irf4.orth_cum_effects[:,0,1], lw=1.5, label='ND4')\n",
    "ax6.plot(irf5.orth_cum_effects[:,0,1], lw=1.5, label='ND5')\n",
    "ax6.plot(irfc.orth_cum_effects[:,0,3], lw=1.5, label='ND6+CERN', color='black')\n",
    "ax6.plot(irfp.orth_cum_effects[:,0,1], lw=1.5, label='PI1+PI2')\n",
    "ax6.plot(irfb.orth_cum_effects[:,0,3], lw=1.5, label='BA1+BA2', color='#0cb6ba')\n",
    "ax6.axhline(y=0, color='grey', alpha=.75)\n",
    "ax6.set_title('f) zPrec -> ESI', x=.05, y=.90, ha='left')\n",
    "ax6.set_xlabel('period (week)', fontsize=12)\n",
    "\n",
    "#ax6.legend(loc=2, ncol=1, frameon=True, fancybox=True, lw=1.5, labelspacing=0.1)\n",
    "\n",
    "f.subplots_adjust(hspace=0.1,wspace=0.275)\n",
    "#f.savefig(fout+'IRF_cumIRF.pdf',bbox_inches='tight', transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = [nd1,nd2,nd3,nd4,nd5,cern,pi1+pi2,ba1+ba2]\n",
    "lrn = ['nd1','nd2','nd3','nd4','nd5','nd6+cern','pi1+pi2','ba1+ba2']\n",
    "dates = ['2002-08','2016-07']\n",
    "w = 30\n",
    "x = .82\n",
    "y = .88\n",
    "a = 0.05\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "params = {'legend.fontsize': 13,\n",
    "         #'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':15,\n",
    "         'xtick.labelsize':13,\n",
    "         'ytick.labelsize':13,\n",
    "         'lines.linewidth':1.2,\n",
    "         'figure.titlesize':20,\n",
    "         #'axes.titleweight': 'bold' \n",
    "         }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "f, ((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2, figsize=(10,14),sharex=True, sharey=True)\n",
    "\n",
    "#\n",
    "ax1.plot(weightaverage(zprec,lr[0]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax1.plot(weightaverage(zgpp,lr[0]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax1.plot(weightaverage(esi,lr[0]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax1.plot(weightaverage(zalbedo,lr[0]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax1.set_title(lrn[0].upper(), x=x, y=y)\n",
    "ax1.axhline(y=0, color='grey')\n",
    "ax1.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax1.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "ax1.set_xlim('2002-10','2016-08')\n",
    "ax1.legend(loc=2, ncol=1, frameon=True, fancybox=True, labelspacing=0.1).get_frame().set_alpha(0.7)\n",
    "\n",
    "ax2.plot(weightaverage(zprec,lr[1]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax2.plot(weightaverage(zgpp,lr[1]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax2.plot(weightaverage(esi,lr[1]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax2.plot(weightaverage(zalbedo,lr[1]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax2.set_title(lrn[1].upper(), x=x, y=y)\n",
    "ax2.axhline(y=0, color='grey')\n",
    "ax2.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax2.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "ax3.plot(weightaverage(zprec,lr[2]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax3.plot(weightaverage(zgpp,lr[2]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax3.plot(weightaverage(esi,lr[2]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax3.plot(weightaverage(zalbedo,lr[2]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax3.set_title(lrn[2].upper(), x=x, y=y)\n",
    "ax3.axhline(y=0, color='grey')\n",
    "ax3.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax3.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "ax4.plot(weightaverage(zprec,lr[3]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax4.plot(weightaverage(zgpp,lr[3]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax4.plot(weightaverage(esi,lr[3]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax4.plot(weightaverage(zalbedo,lr[3]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax4.set_title(lrn[3].upper(), x=x, y=y)\n",
    "ax4.axhline(y=0, color='grey')\n",
    "ax4.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax4.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "ax5.plot(weightaverage(zprec,lr[4]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax5.plot(weightaverage(zgpp,lr[4]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax5.plot(weightaverage(esi,lr[4]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax5.plot(weightaverage(zalbedo,lr[4]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax5.set_title(lrn[4].upper(), x=x, y=y)\n",
    "ax5.axhline(y=0, color='grey')\n",
    "ax5.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax5.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "ax6.plot(weightaverage(zprec,lr[5]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax6.plot(weightaverage(zgpp,lr[5]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax6.plot(weightaverage(esi,lr[5]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax6.plot(weightaverage(zalbedo,lr[5]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax6.set_title(lrn[5].upper(), x=x, y=y)\n",
    "ax6.axhline(y=0, color='grey')\n",
    "ax6.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax6.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "df = weightaverage(zprec,lista=lr[6])\n",
    "df[df > 2.8] = np.nan\n",
    "ax7.plot(df.loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax7.plot(weightaverage(zgpp,lr[6]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax7.plot(weightaverage(esi,lr[6]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax7.plot(weightaverage(zalbedo,lr[6]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax7.set_title(lrn[6].upper(), x=x, y=y)\n",
    "ax7.axhline(y=0, color='grey')\n",
    "ax7.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax7.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "ax8.plot(weightaverage(zprec,lr[7]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zPREC')\n",
    "ax8.plot(weightaverage(zgpp,lr[7]).loc[dates[0]:dates[1]].rolling(w).mean(), label='zGPP')\n",
    "ax8.plot(weightaverage(esi,lr[7]).loc[dates[0]:dates[1]].rolling(w).mean(), label='ESI')\n",
    "ax8.plot(weightaverage(zalbedo,lr[7]).loc[dates[0]:dates[1]].rolling(w).mean(), color='orange',label='zAlbedo')\n",
    "ax8.set_title(lrn[7].upper(), x=x, y=y)\n",
    "ax8.axhline(y=0, color='grey')\n",
    "ax8.axvspan('2002-10','2012-01',alpha=a, color='blue')\n",
    "ax8.axvspan('2012-01','2017-05',alpha=a, color='red')\n",
    "\n",
    "f.subplots_adjust(hspace=0.065,wspace=0.025)\n",
    "f.savefig(fout+'gpp_esi_prec.pdf',bbox_inches='tight', transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fevdc = rc.fevd(10)\n",
    "fevd1 = r1.fevd(10)\n",
    "fevd2 = r2.fevd(10)\n",
    "fevd3 = r3.fevd(10)\n",
    "fevdp = rp.fevd(10)\n",
    "fevdb = rb.fevd(10)\n",
    "#print(fevdc.summary())\n",
    "#print(fevd1.summary())\n",
    "#print(fevdb.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fevdp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granger causality\n",
    "- Does zAlbedo cause ESI?\n",
    "- Does zGPP cause ESI?\n",
    "- Does ESI cause zGPP?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r2.test_causality('ESI',['zAlbedo','zGPP'],kind='f', signif=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb.test_causality('ESI','zAlbedo',kind='f', signif=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb.test_causality('ESI','zGPP',kind='f', signif=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb.test_causality('ESI','zPrec',kind='f', signif=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb.test_causality('zPrec','ESI',kind='f', signif=0.05)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ESI causa em zPrec:\n",
    "1 - causa borderline (0.47)\n",
    "2 - nao causa (0.855)\n",
    "3 - nao cause (0.528)\n",
    "c - causa (0.005)\n",
    "b - nao cause (0.223)\n",
    "p - nao cause (0.210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
